{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Standardized Precipitation Index (SPI)\n",
    "\n",
    "The Standardized Precipitation Index (SPI) is the excess precipitation in a region compared to the historical average, divided by the variance of the historical average. The SPI indicates areas of statistically significant excess or deficit of precipitation. It is defined as\n",
    "\n",
    "$SPI = \\frac{P - P_\\mu}{\\sigma}$\n",
    "\n",
    "Calculating the SPI requires aggregating years of historical data. We push this part of the analytics into a set of PAIRS queries that calculate averages and variances. Subsequently we obtain the SPI after a small amount of additional operations that are done locally.\n",
    "\n",
    "References:\n",
    "- https://climatedataguide.ucar.edu/climate-data/standardized-precipitation-index-spi\n",
    "- http://www.wamis.org/agm/pubs/SPI/WMO_1090_EN.pdf\n",
    "- https://journals.ametsoc.org/doi/10.1175/2009JCLI2909.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"import libraries\")\n",
    "from ibmpairs import paw\n",
    "from datetime import datetime\n",
    "import pandas as pd, numpy as np, os, matplotlib.pyplot as plt, matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some global variables, i.e., the server, user and credentials. This assumes there is a file ibmpairspass.txt in your home directory containing access credentials for IBM PAIRS. This file contains only the line: `pairs.res.ibm.com:username:password`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "# Note you need to edit the file 'ibmpairspass.txt' and add your user id and the PAIRS password  \n",
    "# we supply. that file will work with all PAIRS examples \n",
    "# you also need to put your IBMid userid here \n",
    "PAIRS_USER        = '<userid>' \n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "###############################################################################################\n",
    "\n",
    "PAIRS_SERVER      = 'https://pairs.res.ibm.com'\n",
    "PAIRS_CREDENTIALS = (PAIRS_USER, paw.get_pairs_api_password(PAIRS_SERVER, PAIRS_USER, passFile='ibmpairspass.txt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next line converts datetime objects to strings in ISO 8601-compliant format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso8601 = \"%Y-%m-%dT%H:%M:%SZ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the SPI with PAIRS\n",
    "\n",
    "### Querying the data\n",
    "\n",
    "We use a *user defined functin* (UDF) to push the aggregations necessary for calculating the SPI into the PAIRS query. As usual, it is best to write a function that generates the UDF instead of writing it by hand. This is done by `getPAIRSQueries`.\n",
    "\n",
    "Inputs are the start and end years for determinig averages as well as the year and month for the SPI (`month` and `year_spi`). To construct the queries, the function loops over year assembling a list of layers (`layerList`) to be queried. Each layer has the alias of \"r\" plus the year name. It contains the aggregated sum of the hourly precipitation amounts for that month. The precipitation comes from the dataset `49459`, which contains the total precipitation values according to the ERA5 climate reanalysis.\n",
    "\n",
    "These are the ingredients for three expressions:\n",
    "- The historic average monthly precipitation for the month in question (`\"alias\" : \"ave\"`).\n",
    "- The historic average of the squares of monthly precipitation totals (`\"alias\" : \"ave2\"`).\n",
    "- The calculation of the variance for the month in question from the above (`\"alias\" : \"var\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPAIRSQueries(month, year_spi = 2018, year_start = 2009, year_end = 2017, spatial_coverage = {\"type\" : \"poly\", \"aoi\" : \"38301\"}):\n",
    "    '''\n",
    "    Generates the query JSONs used to calculate the SPI in IBM PAIRS Geoscope.\n",
    "    '''\n",
    "    \n",
    "    if(month!=12):\n",
    "        end_spi = datetime(year_spi, month+1, 1).strftime(iso8601)\n",
    "    else:\n",
    "        end_spi = datetime(year_spi+1, 1, 1).strftime(iso8601)\n",
    "        \n",
    "    layerList = list()\n",
    "    for year in range(year_start, year_end + 1, 1):\n",
    "        \n",
    "        if(month!=12):\n",
    "            end_str = datetime(year, month+1, 1).strftime(iso8601)\n",
    "        else:\n",
    "            end_str = datetime(year+1, 1, 1).strftime(iso8601)\n",
    "            \n",
    "        layer_year = {\n",
    "                 \"alias\" : \"r\" + str(year), \"type\" : \"raster\", \"id\" : \"49459\",\n",
    "                 \"aggregation\" : \"Sum\",\n",
    "                 \"temporal\" : { \"intervals\" : [{\n",
    "                         \"start\" : datetime(year, month, 1).strftime(iso8601),\n",
    "                         \"end\" : end_str }]},\n",
    "                 \"output\" : False}\n",
    "        # append list\n",
    "        layerList.append(layer_year)\n",
    "\n",
    "    # 1st UDF: average\n",
    "    average_udf = dict()\n",
    "    average_udf[\"alias\"] = \"ave\"\n",
    "    average_udf[\"expression\"] = None\n",
    "\n",
    "    # create 'expression' value automatically \n",
    "    str_avg = \"(\"\n",
    "    for year in range(year_start, year_end + 1, 1):\n",
    "        str_avg += '$r' + str(year) + '+'\n",
    "    # - cut last '+' sign     \n",
    "    str_avg = str_avg[0:len(str_avg)-1]\n",
    "    # - add the denominator\n",
    "    str_avg += ')/(' + str(year_end) + '-' + str(year_start) + '+1)'\n",
    "\n",
    "    average_udf[\"expression\"] = str_avg\n",
    "\n",
    "    # 2nd UDF: average of squared values\n",
    "    average2_udf = dict()\n",
    "    average2_udf[\"alias\"] = \"ave2\"\n",
    "    average2_udf[\"expression\"] = None\n",
    "\n",
    "    # create 'expression' value automatically \n",
    "    str_avg2 = \"(\"\n",
    "    for year in range(year_start, year_end + 1, 1):\n",
    "        str_avg2 += '$r' + str(year) + '*' + '$r' + str(year) + '+'\n",
    "    # - cut last '+' sign     \n",
    "    str_avg2 = str_avg2[0:len(str_avg2)-1]\n",
    "    # - add the denominator\n",
    "    str_avg2 += ')/(' + str(year_end) + '-' + str(year_start) + '+1)'\n",
    "\n",
    "    average2_udf[\"expression\"] = str_avg2\n",
    "    \n",
    "    # UDF for variance\n",
    "    variance_udf = {\"alias\" : \"var\", \"expression\" : \"math:sqrt($ave2-$ave*$ave)\"}\n",
    "\n",
    "    # append\n",
    "    layerList.append(average_udf)\n",
    "    layerList.append(average2_udf)\n",
    "    layerList.append(variance_udf)\n",
    "\n",
    "    queryJson = dict()\n",
    "    queryJson = {\"layers\" : layerList,\n",
    "        \"spatial\" : spatial_coverage,\n",
    "        \"temporal\" : {\"intervals\" : [{\"snapshot\" : \"2018-05-31T00:00:00Z\"}]}\n",
    "    }\n",
    "    \n",
    "    alias_str = 'r' + str(year_spi) \n",
    "    queryJson2 = {\n",
    "        \"layers\" : [ \n",
    "            {\n",
    "                \"alias\" : alias_str, \"type\" : \"raster\", \"id\" : \"49459\",\n",
    "                \"aggregation\" : \"Sum\",\n",
    "                \"temporal\" : { \"intervals\" : [{\n",
    "                        \"start\" : datetime(year_spi, month, 1).strftime(iso8601),\n",
    "                        \"end\" : end_spi }]},\n",
    "                \"output\" : True\n",
    "            },\n",
    "        ],\n",
    "        \"spatial\" : spatial_coverage,\n",
    "        \"temporal\" : {\"intervals\" : [{\"snapshot\" : \"2018-05-31T00:00:00Z\"}]}\n",
    "    }\n",
    "    \n",
    "    return queryJson, queryJson2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month, year_spi = 2, 2018\n",
    "queryJson, queryJson2 = getPAIRSQueries(month = month, year_spi = year_spi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit the queries to PAIRS, we wrap the above JSONs in `paw.PAIRSQuery` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = paw.PAIRSQuery(queryJson, PAIRS_SERVER, PAIRS_CREDENTIALS)\n",
    "query2 = paw.PAIRSQuery(queryJson2, PAIRS_SERVER, PAIRS_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.submit()\n",
    "query2.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.poll_till_finished()\n",
    "query2.poll_till_finished()\n",
    "query.download()\n",
    "query2.download()\n",
    "query.create_layers()\n",
    "query2.create_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local calculations and visualizting the result\n",
    "\n",
    "In the following various expressions are made to do the arithmetic, which is the difference between the precipitation in the desired year and the past average for that month, divided by the variance for that month. The results are plotted at the end of the loop over each month. The color range for each plot is determined by the rms of the plotted quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_str = 'r' + str(year_spi) \n",
    "a_str = 'Global weather (ERA5)-Total precipitation[' + alias_str + ']-Sum'\n",
    "a=query2.data[a_str]\n",
    "b=query.data['Expression-ave[ave]-Exp']\n",
    "c=query.data['Expression-var[var]-Exp']\n",
    "c1 = np.array(c) \n",
    "c1[np.isnan(c)]=0\n",
    "ab = np.array(a-b)\n",
    "ab[np.isnan(a-b)]=0\n",
    "minvar=np.nanmin(query.data['Expression-var[var]-Exp'])\n",
    "#print(minvar)\n",
    "c2=c1*ab/((0.5*minvar+c1)*(0.5*minvar+c1))  # this is ab/c1 but avoiding divide by zero\n",
    "amean=np.nanmean(a)\n",
    "arms=np.nanstd(a)\n",
    "print('precip=',amean,arms,amean-arms,amean+arms)\n",
    "#print(a.shape)\n",
    "bmean=np.nanmean(b)\n",
    "brms=np.nanstd(b)\n",
    "print('ave=',bmean,brms,bmean-brms,bmean+brms)\n",
    "#print(b.shape)\n",
    "varmean=np.nanmean(c)\n",
    "varrms=np.nanstd(c)\n",
    "print('var=',varmean,varrms,varmean-varrms,varmean+varrms)\n",
    "#print(c.shape)\n",
    "abmean=np.nanmean(ab)\n",
    "abrms=np.nanstd(ab)\n",
    "print(' diff=',abmean,abrms,abmean-abrms,abmean+abrms)\n",
    "#print(ab.shape)\n",
    "c2mean=np.nanmean(c2)\n",
    "c2rms=np.nanstd(c2)\n",
    "print('pci=',c2mean,c2rms,c2mean-c2rms,c2mean+c2rms)\n",
    "#print(c2.shape)\n",
    "# use these next few lines to make a figure with just the SPI\n",
    "#    plt.figure(figsize = (16, 12))\n",
    "#    plt.imshow(c2, vmin=-2*c2rms, vmax=+2*c2rms, cmap = 'seismic_r')\n",
    "#    plt.colorbar()\n",
    "#    str_title = \"SPI_\" + str(year_spi) + \"_\" + str(month) + \"_\" + \"Americas.png\"\n",
    "#    plt.savefig(str_title , transparent=True, bbox_inches = 'tight')\n",
    "#    plt.show()\n",
    "fig, axes = plt.subplots(2,2, True, True, figsize = (12, 12))\n",
    "axesImage1 = axes[0, 0].imshow(c2, cmap = 'seismic_r', vmin = -2*c2rms, vmax = 2*c2rms)\n",
    "axesImage2 = axes[0, 1].imshow(b, cmap = 'seismic_r', vmin=0, vmax=2*brms)\n",
    "axesImage3 = axes[1, 0].imshow(ab, cmap = 'seismic_r', vmin=-2*abrms, vmax=2*abrms)\n",
    "axesImage4 = axes[1, 1].imshow(c, cmap = 'seismic_r', vmin=0, vmax=varmean+2*varrms)\n",
    "axes[0, 0].set_title('SPI '+str(year_spi)+\"_\"+str(month))\n",
    "axes[0, 1].set_title('Average')\n",
    "axes[1, 0].set_title('Current-Average')\n",
    "axes[1, 1].set_title('Variance')\n",
    "plt.colorbar(axesImage1, ax = axes[0,0], label = 'SPI')\n",
    "plt.colorbar(axesImage2, ax = axes[0,1], label = 'Average')\n",
    "plt.colorbar(axesImage3, ax = axes[1,0], label = 'Current - Average')\n",
    "plt.colorbar(axesImage4, ax = axes[1,1], label = 'Variance')\n",
    "str_title = \"SPI_\" + str(year_spi) + \"_\" + str(month) + \"_\" + \"America.png\"\n",
    "plt.savefig(str_title , transparent=True, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
