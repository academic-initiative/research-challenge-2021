{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demo script to illustrate the power of PAIRS. As we all know, there is a lot of talk on climate change, i.e. whether our climate will change or has changed. While forecasting climate change is an ongoing and complex research topic, we can use PAIRS to find out how much the climate has changed in the last 4 decades? \n",
    "\n",
    "So let's start with the Continental United States. In PAIRS we have the PRISM data sets http://prism.oregonstate.edu/. For example, we have the daily max temperature (id=92) at 4km spatial resolution starting from 1981 until today.\n",
    "\n",
    "The area of the continental US is ~ 8M square km meaning that we have ~2M data points every day for 39 years. To get started let's submit a query to PAIRS to obtain this data for a selected date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibmpairs import paw\n",
    "from datetime import datetime, timedelta\n",
    "import re, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#import h5py\n",
    "\n",
    "###############################################################################################\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "# Note you need to edit the file 'ibmpairspass.txt' and add your user id and the PAIRS password  \n",
    "# we supply. that file will work with all PAIRS examples \n",
    "# you also need to put your IBMid userid here \n",
    "PAIRS_USER        = '<userid>' \n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "###############################################################################################\n",
    "\n",
    "PAIRS_SERVER      = 'https://pairs.res.ibm.com'\n",
    "PAIRS_CREDENTIALS = (PAIRS_USER, paw.get_pairs_api_password(PAIRS_SERVER, PAIRS_USER, passFile='ibmpairspass.txt'))\n",
    "\n",
    "iso8601 = '%Y-%m-%dT%H:%M:%SZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi=24             #AOI=24 is the continental US\n",
    "queryJson = {\n",
    "    \"layers\" : [\n",
    "        {\"type\" : \"raster\", \"id\" : \"92\"}\n",
    "    ],\n",
    "    \"spatial\" : {\"type\" : \"poly\",  \"aoi\" :aoi},\n",
    "    \"temporal\" : {\"intervals\" : [\n",
    "        {\"snapshot\" : \"2018-05-31T00:00:00Z\"}\n",
    "    ]}\n",
    "}\n",
    "query = paw.PAIRSQuery(queryJson, PAIRS_SERVER, PAIRS_CREDENTIALS)\n",
    "query.submit()\n",
    "query.poll_till_finished()\n",
    "query.download()\n",
    "query.create_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a query takes usually a few seconds to run (~40s). \n",
    "Of course, we are interested in finding out whether or not the temperatures have changed in the last 38 years, which means  - naively - one would have to run 39 * 365 = 14235 queries, which would take 158 hours or more than 6 days. \n",
    "\n",
    "The good news is that with PAIRS we can submit such a query without downloading the data with user-defined functions, which we can submit with the query. \n",
    "\n",
    "For this we can write a function (generateQueryJson), which generates the user defined functions in form a json which\n",
    "1. calculates the average values (e.g., maximum temperature) for earch year (for PRISM from 1981 to 2019) for each location\n",
    "2. performs a linear regression to obtain the annual change (e.g. annual temperature change in oC/year) for each location, and\n",
    "3. estimates the standard error of the annual change (e.g. error of the annual temperature change in oC/year) for each location.\n",
    "\n",
    "We also write a simple procedure to view the results (showPAIRSdata), which can also smooth the data for better visualization if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQueryJson(layer_id,agg,startDate,duration,N,aoi):\n",
    "#calculate the average annual value\n",
    "    queryJson = {\n",
    "        'layers' : [\n",
    "            {\n",
    "                'alias' : 'Y{0}'.format(str(years+startDate.year).zfill(2)),\n",
    "                'aggregation' : agg,\n",
    "                'type' : 'raster', \n",
    "                'id' : layer_id,\n",
    "                'temporal' : {'intervals' : [{\n",
    "                    'start' : (startDate.replace(startDate.year + years)).strftime(iso8601),\n",
    "                    'end' : (startDate.replace(startDate.year + years) + timedelta(days = duration)).strftime(iso8601)\n",
    "                }]},\n",
    "                'output' : False\n",
    "            }\n",
    "            for years in range(0,N) ],\n",
    "        'spatial' : {'type' : 'poly',  'aoi' : aoi},\n",
    "        'temporal' : {'intervals' : [{'snapshot' : startDate.strftime(iso8601)}]},\n",
    "    }\n",
    "\n",
    "#calculate the mean of x     \n",
    "    queryJson['layers'].extend([{\n",
    "        'alias' : 'xm',\n",
    "        'expression' : '('+'+'.join([\n",
    "            '{0}'.format(str(years+startDate.year).zfill(2))\n",
    "            for years in range(0,N)\n",
    "        ] \n",
    "        )}\n",
    "    ])\n",
    "    queryJson['layers'][N]['expression']=queryJson['layers'][N]['expression']+')'+'/'+str(N)\n",
    "    queryJson['layers'][N].update({'output' : False})\n",
    "    \n",
    "#calculate the mean of y     \n",
    "    queryJson['layers'].extend([{\n",
    "        'alias' : 'ym',\n",
    "        'expression' : '('+'+'.join([\n",
    "            '$Y{0}'.format(str(years+startDate.year).zfill(2))\n",
    "            for years in range(0,N)\n",
    "        ] \n",
    "        )}\n",
    "    ])\n",
    "    queryJson['layers'][N+1]['expression']=queryJson['layers'][N+1]['expression']+')'+'/'+str(N)\n",
    "    queryJson['layers'][N+1].update({'output' : False})\n",
    "    \n",
    "#calculate Sxx     \n",
    "    queryJson['layers'].extend([{\n",
    "        'alias' : 'Sxx',\n",
    "        'expression' : ' + '.join([\n",
    "            '({0}-$xm)*({0}-$xm)'.format(str(years+startDate.year).zfill(2))\n",
    "            for years in range(0,N)\n",
    "        ] \n",
    "        )}\n",
    "    ])    \n",
    "    queryJson['layers'][N+2].update({'output' : False})\n",
    "\n",
    "#calculate Syy     \n",
    "    queryJson['layers'].extend([{\n",
    "        'alias' : 'Syy',\n",
    "        'expression' : ' + '.join([\n",
    "            '($Y{0}-$ym)*($Y{0}-$ym)'.format(str(years+startDate.year).zfill(2))\n",
    "            for years in range(0,N)\n",
    "        ] \n",
    "        )}\n",
    "    ])\n",
    "    queryJson['layers'][N+3].update({'output' : False})\n",
    "        \n",
    "#calculate Sxy     \n",
    "    queryJson['layers'].extend([{\n",
    "        'alias' : 'Sxy',\n",
    "        'expression' : ' + '.join([\n",
    "            '({0}-$xm)*($Y{0}-$ym)'.format(str(years+startDate.year).zfill(2))\n",
    "            for years in range(0,N)\n",
    "        ] \n",
    "        )}\n",
    "    ])\n",
    "    queryJson['layers'][N+4].update({'output' : False})\n",
    "    \n",
    "#calculate slope\n",
    "    queryJson['layers'].extend([{\n",
    "        'alias' : 'slope',\n",
    "        'expression' : '$Sxy/$Sxx'\n",
    "        }]\n",
    "   )  \n",
    "\n",
    "#calculate standard error \n",
    "    queryJson['layers'].extend([{\n",
    "        'alias' : 'error',\n",
    "        'expression' : 'math:sqrt(($Syy-($Sxy*$Sxy/$Sxx))/($Sxx*'+str(N-2)+'))'\n",
    "        }]\n",
    "   )  \n",
    "    return queryJson\n",
    "\n",
    "def showPAIRSdata(out_id,figuretitle,filename,n,vmin,vmax):\n",
    "    query_metadata = pd.DataFrame(query.metadata).transpose()\n",
    "    out_id=out_id\n",
    "    extent = [\n",
    "        query.metadata[out_id]['details']['boundingBox'][k]\n",
    "        for k in ['minLongitude', 'maxLongitude', 'minLatitude', 'maxLatitude']\n",
    "    ]\n",
    "    out=query.data[out_id]\n",
    "    kernel = np.ones((n,n),np.float32)/n/n\n",
    "    out_filtered = cv2.filter2D(out,-1,kernel)\n",
    "    fig=plt.figure(figsize=(16,8))\n",
    "    plt.imshow(out_filtered, extent = extent, cmap = 'plasma',vmin=vmin,vmax=vmax)\n",
    "    plt.colorbar()\n",
    "    fig.suptitle(figuretitle)\n",
    "    fig.savefig(filename)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Okay now let's look at this query, which generateQueryJson generates. It is quite a lot of (simple) math...:(\n",
    " We also specifiy a start date, the time period (days) and the total numbers of years (N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "startDate = datetime.date(1981,1,1)\n",
    "days=365\n",
    "N=39\n",
    "aggregation='Mean'\n",
    "dset=92\n",
    "# id 92 is Daily max temperature from PRISM - see PAIRS data catalogue\n",
    "queryJson = generateQueryJson(dset,aggregation,startDate,days,N,aoi)\n",
    "queryJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's submit this query and see what happens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = paw.PAIRSQuery(queryJson, PAIRS_SERVER, PAIRS_CREDENTIALS)\n",
    "query.submit()\n",
    "query.poll_till_finished()\n",
    "query.download()\n",
    "query.create_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query takes typically around ~ 7 min, which is more than 1000x faster than downloading each data set. In fact it is even better because we have already computed the answer to our question, which is ready to be viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showPAIRSdata('Expression-slope[slope]-Exp','Prism - Annual temperature change from 1981 to 2019 [oC/year]','Prism-temp.png',1,-0.02,0.06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very interesting. Most places in the US have warmed over the last 39 years with a rate of 0.02 to 0.04 C/year, which means between 0.8 and 1.6C (or 1.4 to 2.8F). The Western and Southwestern part of the US has warmed faster than the eastern part. Parts of the Midwest have seen the least amount of warming or even some cooling. Now let's have a look at the error of this trend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showPAIRSdata('Expression-error[error]-Exp','PRISM - Error of the annual temperature change from 1981 to 2018 [oC/year]','Prism-error.png',n=2,vmin=0.00,vmax=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
